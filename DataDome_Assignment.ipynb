{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160e497f-999f-4ed2-9840-aa6e5a71b932",
   "metadata": {},
   "source": [
    "# DataDome Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934d634-1549-4017-befe-4a908b897d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Identify good bot traffic, i.e. non malicious bots like such as Google Bot\n",
    "'''\n",
    "good_bot_selectors = [\n",
    "    # Google Ads Bot (AdsBot-Google)\n",
    "    # Arquivo web crawler (Heritrix)\n",
    "    # Twitter Bot\n",
    "    # WordPress related bots\n",
    "    # LinkedIn Bot\n",
    "    # HubSpot Ads Link Fetcher\n",
    "    # Feedly Bot\n",
    "    # Capterra Bot\n",
    "    # Asana - Project management tool\n",
    "    # Apache-HttpClient - widely used Java library for making HTTP requests\n",
    "    # AliyunSecBot - Associated with Alibaba Cloud's security scanning service\n",
    "    df['UserAgent'].str.contains(r'AdsBot-Google \\(+', na=False),\n",
    "    df['UserAgent'].str.contains(r'Arquivo-web-crawler \\(compatible', na=False),\n",
    "    df['UserAgent'].str.contains(r'Twitterbot\\/1\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'WordPress\\/6\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'LinkedInBot\\/1.0', na=False),\n",
    "    df['UserAgent'].str.contains(r'HubSpot Ads Link Fetcher\\/1\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'Feedly\\/1\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'CapterraBot', na=False),\n",
    "    df['UserAgent'].str.contains(r'Asana\\/1\\.4\\.0 WebsiteMetadataRetriever', na=False),\n",
    "    df['UserAgent'].str.contains(r'Apache-HttpClient\\/4\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'AliyunSecBot\\/Nutch\\-', na=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443454e-ed1d-4ee4-b403-b4d5ed915f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Identify bad bot traffic. We consider as malicious, all requests from non-identified bots (bots that\n",
    "donâ€™t explicitly state their identity in the user-agent), as well as fake good bots, i.e. bots that pretend\n",
    "to be a good bot in their user-agent (fake google bot from IPs that do not belong to Google). You\n",
    "should use different detection signals and different type of approaches (signatures vs behavioral\n",
    "analysis)\n",
    "'''\n",
    "bad_bot_selectors = [\n",
    "    #bxss\\.me - Blind Cross-Site Scripting (Blind XSS) Bots\n",
    "    #jndi:ldap:// - Outbound LDAP request - highly suspicious/malicious\n",
    "    #oast\\.me - Commonly associated with Out-of-Band Application Security Testing (OAST) tools\n",
    "    #nslookup - Malicious DNS Lookup commands\n",
    "    #\\$\\{sys:os\\.arch\\} - System property lookup, highly suspicious for legitimate traffic\n",
    "    #\\(select\\(0\\)from\\(select\\(sleep\\( - Time-based SQL injection attacks to delay the server's response and confirm the presence of a vulnerability\n",
    "    #&echo|\\|echo - Command Injection (echo)\n",
    "    #@@o9MoK - Suspicious String\n",
    "    #useragent.m413k3936p0j44928gn68xr1otn7271 - Suspicious String\n",
    "    #'../../' - This pattern is commonly associated with path traversal attempts\n",
    "    #'\\containers/json' - detects attempts to access Docker APIs\n",
    "    #allow_url_include|auto_prepend_file - detect attempts to manipulate PHP settings \n",
    "    #fingerprintReferrer- malicious IPs in fingerprintReferrer can be used to detect malicious traffic\n",
    "    #fingerprintClientIp - malicious IPs in fingerprintReferrer can be used to detect malicious traffic\n",
    "    df['UserAgent'].str.contains(r'bxss\\.me', na=False),\n",
    "    df['UserAgent'].str.contains(r'\\$\\{jndi:ldap://', na=False),\n",
    "    df['UserAgent'].str.contains(r'oast\\.me', na=False),\n",
    "    df['UserAgent'].str.contains(r'nslookup', na=False),\n",
    "    df['UserAgent'].str.contains(r'\\$\\{sys:os\\.arch\\}', na=False),\n",
    "    df['UserAgent'].str.contains(r'\\(select\\(0\\)from\\(select\\(sleep\\(', na=False),\n",
    "    df['UserAgent'].str.contains(r'&echo|\\|echo', na=False),\n",
    "    df['UserAgent'].str.contains(r'@@o9MoK', na=False),\n",
    "    df['UserAgent'].str.contains(r'useragent.m413k3936p0j44928gn68xr1otn7271', na=False),\n",
    "    df['fingerprintRequestUrl'].str.contains(r'\\/\\.\\.\\/\\.\\.\\/', na=False),\n",
    "    df['fingerprintRequestUrl'].str.contains(r'\\/containers\\/json', na=False),\n",
    "    df['fingerprintRequestUrl'].str.contains(r'allow_url_include|auto_prepend_file', na=False, case=False),\n",
    "    df['fingerprintReferer'].str.contains(r'\\/\\/38.43.93.42', na=False, case=False),\n",
    "    df['fingerprintClientIp'].str.contains(r'\\/\\/206.123.130.4', na=False, case=False)   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b585d-2f15-4143-8853-5953f2abe496",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Identify human traffic\n",
    "'''\n",
    "humanTraffic = [\n",
    "    # Popular Browsers/OS alogn with the version number\n",
    "    # fingerprintRequestJsWebDriver - True for automation software, strong bot indication\n",
    "    # fingerprintRequestJsWebGlRend - Identifies WebGL rendering capabilities of a browser. GPU names give confidence about real devices and not headless browsers\n",
    "    # fingerprintRequestJsHardwareConcu - Captures the hardware concurrency. Not unique on its own but when used with other indicators that can make a good signature/signal\n",
    "    df['UserAgent'].str.contains(r'Mozilla\\/5\\.0 \\((Windows NT|Linux|Macintosh|SS|CentOS|Debian|Fedora|iPad|iPhone|Knoppix|X11)', na=False, case=False),\n",
    "    df['UserAgent'].str.contains(r'Opera\\/(\\d+\\.\\d+)', na=False, case=False),\n",
    "    df['UserAgent'].str.contains(r'Microsoft Office\\/16\\.0 \\(', na=False, case=False),\n",
    "    df['fingerprintRequestJsWebDriver'].astype(str).str.fullmatch('FALSE', case=False, na=False),\n",
    "    (df['fingerprintRequestJsWebDriver'].astype(str).str.fullmatch('FALSE', case=False, na=False)) &\n",
    "    (df['fingerprintRequestJsWebGlRend'].str.contains('Adreno|Nvidia|ANGLE|Apple|Google|Intel|Mali|Radeon', case=False, na=False)) &\n",
    "    (df['fingerprintRequestJsHardwareConcu'].astype(str).str.match(r'\\d+', na=False))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983be5d-f6fb-431e-9713-66495ca49144",
   "metadata": {},
   "source": [
    "## Discuss your approaches/hypotheses when identifying both good and bad bots\n",
    "\n",
    "Q. Is it based on behavior, HTTP headers, JS information, hybrid information? Also, if you don't use\n",
    "some of these approaches, please explain your choice.\n",
    "\n",
    "For the purpose of this assignment I considered a few indicators \n",
    "- fingerprintClientIp - Malicious IPs or IPs that have detection on popular security portals like VirusTotal can be used as an indicator. Since this IP signifies the IP of the client, a malicious IP can be used as a good indicator for identification\n",
    "- Positives\n",
    "    - Fast detection, easy to automate\n",
    "Negatives\n",
    "    - Its possible that an IP does not have detection when analysis was being done\n",
    "    - If an IP is flagged because of a False Posivie by a different vendor we might get a False Positive if we use this detection as is\n",
    "\n",
    "- fingerprintUserAgent - This field contains useragent of the client. In the given assignment strings present in this field can be used as a good indicator to identify malicious a well as non-malicious traffic\n",
    "- Positives\n",
    "    - Fast detection, easy to automate\n",
    "    - Possible to build a respository of signals/rules for detection\n",
    "- Negatives\n",
    "    - Spoofing the content in this field can throw off detection\n",
    "\n",
    "- fingerprintReferer - This field indicates the referral URL that can be checked for legitimacy. This can indicate where the request came from - a legitimate company, a service provider - which can give hints about the origins and purpose of the traffic\n",
    "- Positives\n",
    "    - Fast detection, easy to automate\n",
    "    - Large number of requests coming from a service provider, home network along with other indicators can indicate suspicious activity (paid bot service usage etc)\n",
    "- Negatives\n",
    "    - Spoofing can be used here, use of anonymizers can lead to dead end as well\n",
    "    - Rapid IP switching can also lead to dead end\n",
    "- fingerprintRequestJsWebGlRend\n",
    "\n",
    "The technique of combining multiple signals is useful in creating robust signatures. In thsi case I used a combination signature to identify good traffic (mostly human traffic). This included using - \n",
    "    1. fingerprintRequestJsWebDriver - True indicates use of automation tools\n",
    "    2. fingerprintRequestJsWebGlRend - WebGL rendering capabilities of a browser, indicating use of actual browsers\n",
    "    3. fingerprintRequestJsHardwareConcu - Hardware concurrency, also indicating normal traffic\n",
    "\n",
    "Lastly I ran a script that checks Virustotal for any detections against a URL. I chose a bunch of IPs from the list and obtained few IPs that have detection. This can be used to further analyze the traffic as only the IP might not be a good indicator as external detections can be False Positives as well.\n",
    "IP can be a good indicator as the below 2 entries seem legitimate considering other headers, but malicious IP address gives an indication that more analysis might be warranted\n",
    "\n",
    "Dec 12, 2024 @ 13:57:29.770\t34.92.43.64\thttp\ttext/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\tdatadome.co\tMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 (StatusCake)\t\t/\tgzip, compress\tGOOGLE-CLOUD-PLATFORM\tHK\ten-US,en;q=0.8\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\n",
    "Dec 12, 2024 @ 17:00:31.840\t34.141.240.181\thttp\ttext/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\tdatadome.co\tMozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:109.0) Gecko/20100101 Firefox/115.0\thttps://reddit.com\t/fr/equipe-datadome/terminer-en-force-demarrer-rapidement-lequipe-de-vente-americaine-de-datadome/\tgzip, br, zstd, deflate\tGOOGLE-CLOUD-PLATFORM\tNL\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f1083-b9ea-4fdf-9a1f-37f8360642af",
   "metadata": {},
   "source": [
    "## Summarize the main strengths and weaknesses of your approaches. Is there any risk of false positives?\n",
    "\n",
    "I have highlighted positives and negatives for most of the indicators that I have used above. In most cases the risk of spoofing poses a threat to cause false positive/negative. We might identify malicious traffic as legitimate due to a rule that was created for a specific component - user agent for example. One way to overcome this is to use multiple signatures in combination rather than a single signature.\n",
    "\n",
    "One of the main strengths in static signatures is that it can detect a big portion of malicious traffic as most of the times perpetrators create tools/services that target broad audience, thereby are created in a quick-and-dirty fashion. This approach lacks mechanisms to counteract signature based security systems. Challenge is to identify the 10-20% of attaks which are designed with a lot of attentino and which try to circumvent security mechanisms.\n",
    "\n",
    "## What would you focus on improving next?\n",
    "\n",
    "Given more time I would like to create more combination-based signatures that take multiple criterias into consideration. These might not catch as many entries as generic signatures but these would be more robust and less prone to false positives\n",
    "\n",
    "\n",
    "## Imagine a customer wants to know more about bot traffic. Create some relevant visualizations (2-3 are enough) to help her/him understand what bots are doing on her/his website and the associated threats. \n",
    "\n",
    "I would take the liberty to provide details that are out of the given test material. \n",
    "\n",
    "I would begin by making the customer think about the possibility of losing customers because of bots as that affects their business directly. I would take uses cases to further hit my point. \n",
    "\n",
    "For this scenario I will consider that the customer owns a business that sells sneakers\n",
    "\n",
    "## Overall, what can you say about the traffic that you analyzed?\n",
    "THe traffic analyzed was a mix of malicious and non-malicious traffic\n",
    "- Malicious traffic included some attempts to exploit the systems using known methods. These can be identified using signals/signatures and this can be improved as we obtain more data\n",
    "- Non-malicious traffic included good bot traffic mainly related to crawling and indexing\n",
    "- There was a lot of human traffic as well which could be identified by few key indicators\n",
    "- Lastly there was human traffic which appeared malicious based onthe IP, these would require further invetigation\n",
    "\n",
    "Overall it gave a good glimpse of regular internet traffic which includes a lof of good as well as bad network activity. It also gave a good high level view of what DataDome researchers have to comb through on a regula basis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
