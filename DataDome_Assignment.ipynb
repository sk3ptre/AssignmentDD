{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160e497f-999f-4ed2-9840-aa6e5a71b932",
   "metadata": {},
   "source": [
    "# DataDome Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934d634-1549-4017-befe-4a908b897d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify good bot traffic, i.e. non malicious bots like such as Google Bot\n",
    "\n",
    "good_bot_selectors = [\n",
    "    # Google Ads Bot (AdsBot-Google)\n",
    "    # Arquivo web crawler (Heritrix)\n",
    "    # Twitter Bot\n",
    "    # WordPress related bots\n",
    "    # LinkedIn Bot\n",
    "    # HubSpot Ads Link Fetcher\n",
    "    # Feedly Bot\n",
    "    # Capterra Bot\n",
    "    # Asana - Project management tool\n",
    "    # Apache-HttpClient - widely used Java library for making HTTP requests\n",
    "    # AliyunSecBot - Associated with Alibaba Cloud's security scanning service\n",
    "    df['UserAgent'].str.contains(r'AdsBot-Google \\(+', na=False),\n",
    "    df['UserAgent'].str.contains(r'Arquivo-web-crawler \\(compatible', na=False),\n",
    "    df['UserAgent'].str.contains(r'Twitterbot\\/1\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'WordPress\\/6\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'LinkedInBot\\/1.0', na=False),\n",
    "    df['UserAgent'].str.contains(r'HubSpot Ads Link Fetcher\\/1\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'Feedly\\/1\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'CapterraBot', na=False),\n",
    "    df['UserAgent'].str.contains(r'Asana\\/1\\.4\\.0 WebsiteMetadataRetriever', na=False),\n",
    "    df['UserAgent'].str.contains(r'Apache-HttpClient\\/4\\.', na=False),\n",
    "    df['UserAgent'].str.contains(r'AliyunSecBot\\/Nutch\\-', na=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443454e-ed1d-4ee4-b403-b4d5ed915f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Identify bad bot traffic. We consider as malicious, all requests from non-identified bots (bots that\n",
    "donâ€™t explicitly state their identity in the user-agent), as well as fake good bots, i.e. bots that pretend\n",
    "to be a good bot in their user-agent (fake google bot from IPs that do not belong to Google). You\n",
    "should use different detection signals and different type of approaches (signatures vs behavioral\n",
    "analysis)\n",
    "'''\n",
    "bad_bot_selectors = [\n",
    "    #bxss\\.me - Blind Cross-Site Scripting (Blind XSS) Bots\n",
    "    #jndi:ldap:// - Outbound LDAP request - highly suspicious/malicious\n",
    "    #oast\\.me - Commonly associated with Out-of-Band Application Security Testing (OAST) tools\n",
    "    #nslookup - Malicious DNS Lookup commands\n",
    "    #\\$\\{sys:os\\.arch\\} - System property lookup, highly suspicious for legitimate traffic\n",
    "    #\\(select\\(0\\)from\\(select\\(sleep\\( - Time-based SQL injection attacks to delay the server's response and confirm the presence of a vulnerability\n",
    "    #&echo|\\|echo - Command Injection (echo)\n",
    "    #@@o9MoK - Suspicious String\n",
    "    #useragent.m413k3936p0j44928gn68xr1otn7271 - Suspicious String\n",
    "    #'../../' - This pattern is commonly associated with path traversal attempts\n",
    "    #'\\containers/json' - detects attempts to access Docker APIs\n",
    "    #allow_url_include|auto_prepend_file - detect attempts to manipulate PHP settings \n",
    "    #fingerprintReferrer- malicious IPs in fingerprintReferrer can be used to detect malicious traffic\n",
    "    #fingerprintClientIp - malicious IPs in fingerprintReferrer can be used to detect malicious traffic\n",
    "    df['UserAgent'].str.contains(r'bxss\\.me', na=False),\n",
    "    df['UserAgent'].str.contains(r'\\$\\{jndi:ldap://', na=False),\n",
    "    df['UserAgent'].str.contains(r'oast\\.me', na=False),\n",
    "    df['UserAgent'].str.contains(r'nslookup', na=False),\n",
    "    df['UserAgent'].str.contains(r'\\$\\{sys:os\\.arch\\}', na=False),\n",
    "    df['UserAgent'].str.contains(r'\\(select\\(0\\)from\\(select\\(sleep\\(', na=False),\n",
    "    df['UserAgent'].str.contains(r'&echo|\\|echo', na=False),\n",
    "    df['UserAgent'].str.contains(r'@@o9MoK', na=False),\n",
    "    df['UserAgent'].str.contains(r'useragent.m413k3936p0j44928gn68xr1otn7271', na=False),\n",
    "    df['fingerprintRequestUrl'].str.contains(r'\\/\\.\\.\\/\\.\\.\\/', na=False),\n",
    "    df['fingerprintRequestUrl'].str.contains(r'\\/containers\\/json', na=False),\n",
    "    df['fingerprintRequestUrl'].str.contains(r'allow_url_include|auto_prepend_file', na=False, case=False),\n",
    "    df['fingerprintReferer'].str.contains(r'\\/\\/38.43.93.42', na=False, case=False),\n",
    "    df['fingerprintClientIp'].str.contains(r'\\/\\/206.123.130.4', na=False, case=False)   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b585d-2f15-4143-8853-5953f2abe496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify human traffic\n",
    "humanTraffic = [\n",
    "    # Popular Browsers/OS alogn with the version number\n",
    "    df['UserAgent'].str.contains(r'Mozilla\\/5\\.0 \\((Windows NT|Linux|Macintosh|SS|CentOS|Debian|Fedora|iPad|iPhone|Knoppix|X11)', na=False, case=False),\n",
    "    df['UserAgent'].str.contains(r'Opera\\/(\\d+\\.\\d+)', na=False, case=False),\n",
    "    df['UserAgent'].str.contains(r'Microsoft Office\\/16\\.0 \\(', na=False, case=False),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983be5d-f6fb-431e-9713-66495ca49144",
   "metadata": {},
   "source": [
    "## Discuss your approaches/hypotheses when identifying both good and bad bots\n",
    "\n",
    "Q. Is it based on behavior, HTTP headers, JS information, hybrid information? Also, if you don't use\n",
    "some of these approaches, please explain your choice.\n",
    "\n",
    "For the purpose of this assignment I considered a few indicators \n",
    "- fingerprintClientIp - Malicious IPs or IPs that have detection on popular security portals like VirusTotal can be used as an indicator. Since this IP signifies the IP of the client, a malicious IP can be used as a good indicator for identification\n",
    "- Positives\n",
    "    - Fast detection, easy to automate\n",
    "Negatives\n",
    "    - Its possible that an IP does not have detection when analysis was being done\n",
    "    - If an IP is flagged because of a False Posivie by a different vendor we might get a False Positive if we use this detection as is\n",
    "\n",
    "\n",
    "fingerprintUserAgent - This field contains useragent of the client. In the given assignment strings present in this field can be used as a good indicator to identify malicious a well as non-malicious traffic\n",
    "Positives\n",
    "    - Fast detection, easy to automate\n",
    "    -  Possible to build a respository of signals/rules for detection\n",
    "Negatives\n",
    "    - Spoofing the content in this field can throw off detection\n",
    "\n",
    "\n",
    "fingerprintReferer - This field indicates the referral URL\n",
    "\n",
    "\n",
    "check\n",
    "fingerprintReferer\n",
    "fingerprintRequestUrl\n",
    "\n",
    "\n",
    "apiEndpoint \n",
    "\n",
    "\n",
    "\n",
    "- \n",
    "\n",
    "What would you focus on improving next?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
